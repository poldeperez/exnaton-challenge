# Exnaton Challenge

## Overview

This project is a full-stack application available at http://16.170.192.128:3000/ 

It is designed for energy data visualization and analytics of customers' installations. The data that was available has been classified as energy consumption and as energy production from a photovoltaic installation. There's a big correlation with the times that the energy is most consumed throughout the days and with the stable consumption during low hours. With solar energy produced there's a strong correlation with the sunlight available at each hour and how it can be very different between some days because of the weather.

The app is designed to show multiple installations per tenant. That means that if a user has access to different installations, they will have the option to switch between them with a dropdown selector. However, In the deployed app there's only the provided data for one installation. It's important to note that one installation can only belong to one user:
- Tenant -> multiple installations
- Installation -> 1 tenant

In the main Overview page, 3 charts are shown:
- Energy consumption vs Solar production
- Analysis of solar energy production: how much of the energy produced is actually consumed (rest is fed to the grid)
- Analysis of energy consumption: how much of the energy consumed comes from renewable source (rest is consumed from the grid)

The filters available are: 
- Installation (only 1 available in original data) 
- Date (only February 2023 available in original data)
- Time aggregation: daily, weekly, monthly and yearly

## Data processing (Task B)

The data is processed with a backend function that processes a json from an external url like the ones that are provided and inserts the values into a meter_readings table in a postgreSQL database. This table is created from the nest entity on starting the backend server and has the following columns:
- id: autogenerated and unique
- tenantId: identifies user and the intallations that has access to
- installationId: must be installation-xxx
- meterId: muid in the json
- obisCode: key of value (0100011D00FF, 0100021D00FF)
- value: energy value
- timestamp: auto
- quality: always 'measured'

This data is accessed with the following endpoints:
- api/meterdata/installations
- api/meterdata/measurement

All the information about these and the other endpoints is documented with swagger docs at http://16.170.192.128:3000/api/docs.

For now the tenant is passed in the header from an environment variable. The logical next step in development would be to implement a system of generating a jwt token associated to the tenant after a login and to send that in the header as a bearer token in all requests to the backend to then be able to obtain the right data from the user.


## Deployment (Task C)

The app is deployed with AWS into an EC2 instance. Using a CI/CD pipeline with Github Actions:
- **CI**: GitHub Actions runs lint, tests and builds on every new PR created.
- **CD**: On merge to main, GitHub Actions deploys to the EC2 instance via SSH and runs `docker-compose up -d --build`.

I opted for Docker Compose over Kubernetes to maintain a lean development environment. While Kubernetes is powerful for large-scale distributed systems, Docker Compose can be more appropiate tool for this architecture.

To deploy in local, besides intalling the necessary dependencies it would be necessary to configure the environment variables in the root of the project (.env).

Bottle necks:

- Querying the database. Mitigations: Adding indexes to the table, calculations done in the sql for faster performance. Also caching in the frontend (react-query) and in the backend (Redis and nest-cache-manager).

---

## Architecture

It consists of a **backend** (NestJS, PostgreSQL, Redis) and a **frontend** (Next.js, React, TypeScript).

### Prerequisites

- Node.js (v24+). There's a .nvmrc file to set the node version 
- Docker & Docker Compose
- PostgreSQL & Redis (if not using Docker)

### Frontend

Next.js app on top of React for dashboards, charts and user interaction.

Component structure with client and server side rendering. Use of states and properties to handle user interactions and data passed down into the charts. Implemented the QueryClientProvider and custom hooks to fetch data with useQuery (React-query) to cache requests with the same time interval, date and installation id. This way the backend is not repeatedly called to fetch the data. 

CSS is configured via Tailwind.

After the data is loaded into the DB, there's only 2 calls to the Nest API from the frontend defined in frontend/lib/api/meter.ts:
- fetchInstallations: Gets all the installations associated with the user (installationId and tenantId columns). Runs on mount of the page.
- fetchMeterData: Gets the aggregated data for the tenant-intallation pair with all the filter parameters and returns values with: timestamp, solar production value, consumption value and the self_consumption calculated in the db.

CORS is handled in the frontend with Next.js rewriting the configuration to proxy API requests to the backend. While this simplifies the initial setup for this challenge, it is not an ideal long-term solution. Scaling this architecture would involve configuring CORS headers directly in the NestJS backend. This would mean taht the client would communicate with the API directly, reducing the Next.js server's overhead and preventing unnecessary 'double-handling' of data bandwidth as user traffic increases.

### Backend

NestJS REST API on top of Node.js handles authentication, business logic and data aggregation.

- **Database**: PostgreSQL for persistent storage, Redis for caching. Leverages TypeORM for standard CRUD operations, while utilizing optimized raw SQL for high-performance self-consumption calculations.
- **Swagger docs**: documentation of API endpoints.
- **Deployment**: Docker Compose for local/dev, GitHub Actions for CI/CD, EC2 for production.

---

## Deployment

- **CI**: GitHub Actions runs lint, tests, and builds on every new PR created.
- **CD**: On merge to `main`, GitHub Actions deploys to the EC2 instance via SSH and runs `docker-compose up -d --build`.

---

## Technologies

- **Backend**: NestJS, TypeORM, PostgreSQL, Redis
- **Frontend**: Next.js, React, TypeScript, Tailwind CSS
- **DevOps**: Docker, Docker Compose, GitHub Actions, AWS EC2

---

## Future steps

Create a Log in page to pass a jwt token for authenticating requests

Develop an Analysis page

User functionalities: Profile/settings/Log out
